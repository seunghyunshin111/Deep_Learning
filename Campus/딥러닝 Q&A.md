# 딥러닝 Q&A

- 딥러닝 기반이 되는 분석 모형?

  인공신경망

- 딥러닝?

  딥러닝은 머신러닝의 특정한 한 분야로서 연속된 층(Layer)에서 점진적으로 의미 있는 표현을 학습하는데 강점

  최근의 딥러닝 모델은 표현 학습을 위해 수십 개, 수백 개의 연속된 층을 가지고 있음

  딥러닝의 각 층들은 모두 훈련 데이터에 노출해 자동으로 학습을 시킴

- 훈련 데이터에서 신경망의 성능을 측정하는 방법으로 네트워크가 옳은 방향으로 학습될 수 있도록 돕는 지표값?

  손실함수

- 비용(cost) 함수를 분류형 모형에 적합하도록 정의한 keras code?

```python
network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])
```

- 다층 신경망에서는 은닉층의 개수가 많아질수록, 즉 신경망이 깊어질수록 학습 속도가 더뎠고, 학습이 제대로 이루어지지 않는 경우가 많다. 오류 역전파 알고리즘을 사용해도 여러 은닉층을 거치며 역방향으로 전파되는 오류가 점점 소실되는 문제가 발생하는데, 이를 무엇이라 하는가?

  그래디언트 소실

- 신경망의 핵심은 층이다. 케라스에서는 이러한 layer를 적절한 텐서 포맷과 데이터 처리방식에 따라 다양하게 지원하는데, (samples, features) 크기의 2D 텐서가 저장된 간단한 벡터 데이터는 완전 연결층이나 밀집층이라고 불리는 층으로도 처리할 수 있다. 이러한 특징을 가진 층을 생성하고자 할 때 사용하는 클래스는?

  Dense

- 손실함수를 기반으로 그 결과값을 최소화하는 모델의 인자를 찾는것, 미분을 통해 기울기를 구한 후, 해당 방향의 반대 방향으로 점근적으로 나아가는 방식으로 값을 찾아가는 것은?

  Optimizer

- 산업용 데이터로 다양한 비정형데이터인 텍스트를 다루는 경우가 많다. 텍스트를 신경망 모델에 적용하려면 텍스트 원본을 그대로 입력으로 사용할 수 없어 변환 과정을 거쳐야 한다. 이와 같이 텍스트를 수치형 텐서로 변환하는 과정을 무엇이라 하는가?

  텍스트 벡터화

- 원-핫 인코딩?

  원-핫 인코딩으로 변환된 벡터는 희소(sparse)하고 대부분 0으로 채워진다.

- 단어를 위해 밀집된 저차원 임베딩 공간을 비지도 학습 방법으로 계산하는 아이디어는 요수아 벤지오 등이 2000년대 초에 등장했다. 산업 애플리케이션에 적용되기 시작된 것은 이 알고리즘이 등장한 이후이다. 이 알고리즘은 2013년 구글의 토마스 미코로프가 개발했으며, 가장 유명하고 성공적인 단어 임베딩 방법이기도 하다. 이것은 무엇인가?

  Word2Vec

- Keras 모델에서 단어 임베딩 학습을 위해 사용할 수 있는 층(Layer)은?

  Embedding

- 모든 자연언어 처리의 응용분야에서 공통적으로 필요로 하는 전처리 작업으로, 의미를 가지는 최소 단위이며 더 이상 분석할 수 없는 가장 작은 말의 단위로 쪼개는 처리?

  형태소 분석

- 대부분의 신경망의 특징은 메모리가 없다는 것이다. 네트워크에 주입되는 입력은 개별적으로 처리되며 입력간에 유지되는 상태가 없다. 이와는 반대로 사람이 문장을 읽는 것처럼 이전의 나온 것을 기억하면서 단어별 또는 한눈에 들어오는 만큼씩 처리할 수 있어야 한다. 다음 중 적합한 기법은?

  RNN

- Keras에서 간단한 순환층을 구현하는 데에 사용하는 층은?

  SimpleRNN

- Keras의 SimpleRNN은 이론적으로 시간 t에서 이전의 모든 타임 스텝의 정보를 유지할 수 있다. 하지만 실제로는 층이 많은 일반 네트워크(피드포워드 네트워크)에서 나타나는 것과 비슷한 현상인 그래디언트 소실 문제로 인해 긴 시간에 걸쳐 의존성은 학습할 수 없는 것이 문제다. 이를 해결하기 위해 고안된 모델은?

  LSTM



